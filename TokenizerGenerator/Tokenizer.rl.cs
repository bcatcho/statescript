// This file is AUTOGENERATED with RAGEL
// !!DO NOT EDIT!! Change the RL file and compile with Ragel
// http://www.colm.net/open-source/ragel/
using System;
using System.Collections.Generic;

namespace Statescript.Compiler
{
   /// <summary>
   /// Tokenizer performs lexical analysis on a string of characters using the
   /// and emits a string of tokens for the Parser to analyze.
   /// </summary>
   public class Tokenizer
   {
      int _lineNumber = 0;
      bool _tokenUncommitted;
      int _tokenStart { get { return _token.StartIndex; } }
      Token _token;
      private List<Token> _tokens;
      char[] _data;
      // ragel properties
      private int cs;
      int p;

      private void StartToken(TokenType tokenType)
      {
        log(string.Format("start {0}", tokenType));
        _token = new Token {
            LineNumber = _lineNumber,
            StartIndex = p,
            TokenType = tokenType
        };
        _tokenUncommitted = true;
      }

      private void StartOperatorToken(TokenOperator tokenOperator)
      {
        log(string.Format("start {0}", tokenOperator));
        _token = new Token {
            LineNumber = _lineNumber,
            StartIndex = p,
            Operator = tokenOperator,
            TokenType = TokenType.Operator,
        };
        _tokenUncommitted = true;
      }

      private void log(string msg) {
        Console.WriteLine(string.Format("{0} {1}", p, msg));
      }

      private void logEnd(string msg) {
        var token = new String(_data, _tokenStart, p - _tokenStart);
        Console.WriteLine(string.Format("{0} {1}: {2}", p, msg, token));
      }

      private void EmitToken() {
        log(string.Format("emit {0}", _token.TokenType));
        _token.Length = p - _tokenStart;
        _tokens.Add(_token);
        _tokenUncommitted = false;
      }

      private void EmitNewLine() {
        _token.TokenType = TokenType.NewLine;
        log(string.Format("emit {0}", _token.TokenType));
        _tokens.Add(_token);
        _tokenUncommitted = false;
      }

      private void CommitLastToken() {
        if (_tokenUncommitted) {
          EmitToken();
        }
      }

      %%{
        machine Tokenizer;
        include TokenizerDef "TokenizerDef.rl";
        write data;
      }%%

      ///<summary>
      /// This method will perform lexical analysis on the character sequence input
      //  and will return a sequence of tokens for the Parser to analyze.
      ///</summary>
      ///<returns>
      /// A sequence of tokens that the Parser can use to Analyze.
      ///</returns>
      public List<Token> Tokenize(char[] data, int len)
      {
         %% write init;
         if (_tokens == null) {
           _tokens = new List<Token>(128);
         }
         _tokens.Clear();
         _lineNumber = 1; // start at line 1 like most text editors
         _data = data;
         p = 0;
         int pe = len;
         int eof = len;
         %% write exec;
         CommitLastToken();
         return _tokens;
      }

      ///<summary>
      /// Call this method after Tokenize to know if the parser exited prematurely
      /// due to an error.
      ///</summary>
      ///<returns>
      /// A boolean indicating if the tokenizer made it to the end of the input or not.
      ///</returns>
      public bool DidReachEndOfInput()
      {
         return (cs >= Tokenizer_first_final);
      }
   }
}
